

Breadth First Search/Traversal - BSF
	Level order Traversal  - DFS
Depth First Search/Traversal
	Preorder/Inorder/Postorder Traversal

BFS
===

// Driver program to test methods of graph class 
int main() 
{ 
    // Create a graph given in the above diagram 
    Graph g(4); 
    g.addEdge(0, 1); 
    g.addEdge(0, 2); 
    g.addEdge(1, 2); 
    g.addEdge(2, 0); 
    g.addEdge(2, 3); 
    g.addEdge(3, 3); 
  
    cout << "Following is Breadth First Traversal "
         << "(starting from vertex 2) \n"; 
    g.BFS(2); 
  
    return 0; 
} 

class Graph 
{ 
    int V;    // No. of vertices 
  
    // Pointer to an array containing adjacency 
    // lists 
    list<int> *adj;    
public: 
    Graph(int V);  // Constructor 
  
    // function to add an edge to graph 
    void addEdge(int v, int w);  
  
    // prints BFS traversal from a given source s 
    void BFS(int s);   
}; 
  
Graph::Graph(int V) 
{ 
    this->V = V; 
    adj = new list<int>[V]; 
} 
  
void Graph::addEdge(int v, int w) 
{ 
    adj[v].push_back(w); // Add w to v’s list. 
} 
  
void Graph::BFS(int s) 
{ 
    // Mark all the vertices as not visited 
    bool *visited = new bool[V]; 
    for(int i = 0; i < V; i++) 
        visited[i] = false; 
  
    // Create a queue for BFS 
    list<int> queue; 
  
    // Mark the current node as visited and enqueue it 
    visited[s] = true; 
    queue.push_back(s); 
  
    // 'i' will be used to get all adjacent 
    // vertices of a vertex 
    list<int>::iterator i; 
  
    while(!queue.empty()) 
    { 
        // Dequeue a vertex from queue and print it 
        s = queue.front(); 
        cout << s << " "; 
        queue.pop_front(); 
  
        // Get all adjacent vertices of the dequeued 
        // vertex s. If a adjacent has not been visited,  
        // then mark it visited and enqueue it 
        for (i = adj[s].begin(); i != adj[s].end(); ++i) 
        { 
            if (!visited[*i]) 
            { 
                visited[*i] = true; 
                queue.push_back(*i); 
            } 
        } 
    } 
} 
  

Output:
Following is Breadth First Traversal (starting from vertex 2)
2 0 3 1

Greedy Algorithm:
==================

Ref : http://www.geeksforgeeks.org/greedy-algorithms-set-1-activity-selection-problem/

An optimization problem can be solved using Greedy if the problem has the following property: 
At every step, we can make a choice that looks best at the moment, and we get the optimal solution of the complete problem.

It is more efficient than other techniques.

Following some standard algorithm which are Greedy algorithms:
1. Krushkal's Minimum Spanning Tree (MST):
	e.g. Problem : Activity Selection
		You are given n activities with their start and finish times. Select the maximum number of activities that can be performed by a single person, 
		assuming that a person can only work on a single activity at a time.
		Example:

		Consider the following 6 activities.
			 start[]  =  {1, 3, 0, 5, 8, 5};
			 finish[] =  {2, 4, 6, 7, 9, 9};
		The maximum set of activities that can be executed 
		by a single person is {0, 1, 3, 4}
		Sol: check for start time of activity is greater than the end time of privious activity.
		
What is Minimum Spanning Tree?
Given a connected and undirected graph, a spanning tree of that graph is a subgraph that is a tree and connects all the vertices together. 
A single graph can have many different spanning trees. A minimum spanning tree (MST) or minimum weight spanning tree for a weighted, 
connected and undirected graph is a spanning tree with weight less than or equal to the weight of every other spanning tree. 
The weight of a spanning tree is the sum of weights given to each edge of the spanning tree

Below are the steps for finding MST using Kruskal’s algorithm
(http://www.geeksforgeeks.org/greedy-algorithms-set-2-kruskals-minimum-spanning-tree-mst/)
1. Sort all the edges in non-decreasing order of their weight.
2. Pick the smallest edge. Check if it forms a cycle with the spanning tree 
formed so far. If cycle is not formed, include this edge. Else, discard it.  
3. Repeat step#2 until there are (V-1) edges in the spanning tree.

The step#2 uses Union-Find algorithm to detect cycle. So we recommend to read following post as a prerequisite.
Union-Find Algorithm | Set 1 (Detect Cycle in a Graph)
Union-Find Algorithm | Set 2 (Union By Rank and Path Compression)

// a structure to represent a weighted edge in graph
struct Edge
{
    int src, dest, weight;
};
 
// a structure to represent a connected, undirected and weighted graph
struct Graph
{
    // V-> Number of vertices, E-> Number of edges
    int V, E;
 
    // graph is represented as an array of edges. Since the graph is
    // undirected, the edge from src to dest is also edge from dest
    // to src. Both are counted as 1 edge here.
    struct Edge* edge;
};
 
// Creates a graph with V vertices and E edges
struct Graph* createGraph(int V, int E)
{
    struct Graph* graph = (struct Graph*) malloc( sizeof(struct Graph) );
    graph->V = V;
    graph->E = E;
 
    graph->edge = (struct Edge*) malloc( graph->E * sizeof( struct Edge ) );
 
    return graph;
}
 
// A structure to represent a subset for union-find
struct subset
{
    int parent;
    int rank;
};
 
// A utility function to find set of an element i
// (uses path compression technique)
int find(struct subset subsets[], int i)
{
    // find root and make root as parent of i (path compression)
    if (subsets[i].parent != i)
        subsets[i].parent = find(subsets, subsets[i].parent);
 
    return subsets[i].parent;
}
 
// A function that does union of two sets of x and y
// (uses union by rank)
void Union(struct subset subsets[], int x, int y)
{
    int xroot = find(subsets, x);
    int yroot = find(subsets, y);
 
    // Attach smaller rank tree under root of high rank tree
    // (Union by Rank)
    if (subsets[xroot].rank < subsets[yroot].rank)
        subsets[xroot].parent = yroot;
    else if (subsets[xroot].rank > subsets[yroot].rank)
        subsets[yroot].parent = xroot;
 
    // If ranks are same, then make one as root and increment
    // its rank by one
    else
    {
        subsets[yroot].parent = xroot;
        subsets[xroot].rank++;
    }
}
 
// Compare two edges according to their weights.
// Used in qsort() for sorting an array of edges
int myComp(const void* a, const void* b)
{
    struct Edge* a1 = (struct Edge*)a;
    struct Edge* b1 = (struct Edge*)b;
    return a1->weight > b1->weight;
}
 
// The main function to construct MST using Kruskal's algorithm
void KruskalMST(struct Graph* graph)
{
    int V = graph->V;
    struct Edge result[V];  // Tnis will store the resultant MST
    int e = 0;  // An index variable, used for result[]
    int i = 0;  // An index variable, used for sorted edges
 
    // Step 1:  Sort all the edges in non-decreasing order of their weight
    // If we are not allowed to change the given graph, we can create a copy of
    // array of edges
    qsort(graph->edge, graph->E, sizeof(graph->edge[0]), myComp);
 
    // Allocate memory for creating V subsets
    struct subset *subsets =
        (struct subset*) malloc( V * sizeof(struct subset) );
 
    // Create V subsets with single elements
    for (int v = 0; v < V; ++v)
    {
        subsets[v].parent = v;
        subsets[v].rank = 0;
    }
 
    // Number of edges to be taken is equal to V-1
    while (e < V - 1)
    {
        // Step 2: Pick the smallest edge. And increment the index
        // for next iteration
        struct Edge next_edge = graph->edge[i++];
 
        int x = find(subsets, next_edge.src);
        int y = find(subsets, next_edge.dest);
 
        // If including this edge does't cause cycle, include it
        // in result and increment the index of result for next edge
        if (x != y)
        {
            result[e++] = next_edge;
            Union(subsets, x, y);
        }
        // Else discard the next_edge
    }
 
    // print the contents of result[] to display the built MST
    printf("Following are the edges in the constructed MST\n");
    for (i = 0; i < e; ++i)
        printf("%d -- %d == %d\n", result[i].src, result[i].dest,
                                                   result[i].weight);
    return;
}

Time Complexity: O(ElogE) or O(ElogV). Sorting of edges takes O(ELogE) time. After sorting, 
we iterate through all edges and apply find-union algorithm. The find and union operations can take atmost O(LogV) time. 
So overall complexity is O(ELogE + ELogV) time. The value of E can be atmost O(V2), so O(LogV) are O(LogE) same. 
Therefore, overall time complexity is O(ElogE) or O(ElogV)


TO DO : 
1. Understand Union-Find algorithm to detect cycle. - DONE
2. try to compile code for above problem/Krushkal algo. - DONE

2. Huffman coding Greedy Algo:
Ref : Ref: http://www.geeksforgeeks.org/greedy-algorithms-set-3-huffman-coding/
Huffman coding is a lossless data compression algorithm. The idea is to assign variable-legth codes to input characters, 
lengths of the assigned codes are based on the frequencies of corresponding characters. 
The most frequent character gets the smallest code and the least frequent character gets the largest code.

There are mainly two major parts in Huffman Coding
1) Build a Huffman Tree from input characters.
2) Traverse the Huffman Tree and assign codes to characters.

Time complexity : O(nlogn)

struct HeapNode
{
	char _data;
	unsigned _freq;
	HeapNode* left, *right;
	HeapNode(char data, unsigned freq)
	{
		_data = data;
		_freq = freq;
		
		left = right = NULL;
	}
};

PrintCode(HeapNode* rt, string str)
{
	if(! rt)	return;
	if(rt->data != "$")
		cout<<"rt->data"<<str;
	
	printCode(rt->left, str+"0");
	printCode(rt->right, str+"1");
}

struct compare
{
	bool operator ()(HeapNode* l, HeapNode* r)
	{
		return (l->freq > r->freq);
	}
}

HuffmanCode(char data[], int freq[], int size)
{
	HeapNode* left, *right, *top;
	
	priority_queue<HeapNode*, vector<HeapNode*>, compare> minHeap;
	
	for(int i=0; i<size; i++)
		minHeap.pushback(new HeapNode(data[i], freq[i]));
	
	while(minHeap.size() != 1)
	{
		left = minHeap.top();
		minHeap.pop();
		right = minHeap.top();
		minHeap.pop();
		
		top = new HeapNode("$", left->freq+right->freq);
		top->left = left;
		top->right = right;
		minHeap.push(top);
	}
	printCode(minHeap.top(), "");
}


3. Prims Algo for MST
1) Create a set mstSet that keeps track of vertices already included in MST.
2) Assign a key value to all vertices in the input graph. 
	Initialize all key values as INFINITE. Assign key value as 0 for the first vertex so that it is picked first.
3) While mstSet doesn’t include all vertices
….a) Pick a vertex u which is not there in mstSet and has minimum key value.
….b) Include u to mstSet.
….c) Update key value of all adjacent vertices of u. To update the key values, 
	iterate through all adjacent vertices. For every adjacent vertex v, 
	if weight of edge u-v is less than the previous key value of v, update the key value as weight of u-v
Time complexity:
Graph represented by adjacency Matrix  : O(n*n)
Adjacency List : 
	Adjacency list traverse by BFS : O(V+E)
	Min Heap(priority queue) : O(log V)

Difference between Kruskal’s and Prims algo:
In Prims while selecting the next vertext it should be smallest among the rest of other connected vertext to the current one.
But this is not the case in Krushkals the next vertext must be smallest not necessorilly connected to current vertext.

4. Dijkstra’s : 
Below are the detailed steps used in Dijkstra’s algorithm to find the shortest path from a single source vertex to all other vertices in the given graph.
Algorithm
1) Create a set sptSet (shortest path tree set) that keeps track of vertices included in shortest path tree, 
	i.e., whose minimum distance from source is calculated and finalized. Initially, this set is empty.
2) Assign a distance value to all vertices in the input graph. Initialize all distance values as INFINITE. 
	Assign distance value as 0 for the source vertex so that it is picked first.
3) While sptSet doesn’t include all vertices
	….a) Pick a vertex u which is not there in sptSetand has minimum distance value.
	….b) Include u to sptSet.
	….c) Update distance value of all adjacent vertices of u. To update the distance values, iterate through all adjacent vertices. For every adjacent vertex v, if sum of distance value of u (from source) and weight of edge u-v, is less than the distance value of v, then update the distance value of v.



===========================================================
						Hash Table
===========================================================
Existing data structure for search have time complexity:
	link list : n
	binary search : log n
	hash table : 1

1. Hashing and Hash table in data structure and Algo
Hash function:
1. Division Method
2. Multiplication method
	Collision may happened in both methods.

2. Good hash functions properties:
	1. Easy compute
	2. Even distribution
	3. Less collision

3. Collision:
	Resolved by chaining.
Load factor:
	= Number of elements / Table size

4. Collision resolution with open addressing
	(linear probing)
	- Remove extra memory and data structure
	- searching is problematic 
	- But table size should be equal to or greater than number of elements.
	- clustering
	
5. Quadratic probing
	h(x) = (T(x) +  	f(i))/mod T_size
	here , f(i) = i*i;
	
Open hashing : use link list to avoid collision occurs
closed hashing : find the another empty place in table itself to avoid collision

6. Double hashing collision Resolution
	used second hashing if collision occurs.
	e.g. hash2 : r - (x % r)
	r = any prime number
	x = number to be hashed into hash table.
	

Application uses Hash Table:

C++ compiler:
uses hash table to track of variable/functions etc used and their defination with line number.

 
 